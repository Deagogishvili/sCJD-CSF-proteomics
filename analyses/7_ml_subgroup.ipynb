{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-versus-Rest Classification for CJD Subtype Analysis\n",
    "\n",
    "This notebook implements a binary classification approach to identify protein signatures specific to each CJD subtype using Random Forest models.\n",
    "\n",
    "## Analysis Approach\n",
    "1. **Binary Classification**: Convert the multiclass problem into one-versus-rest binary classification for each subtype\n",
    "2. **Class Imbalance**: Address class imbalance using weighted Random Forest\n",
    "3. **Feature Selection**: Perform feature selection within each cross-validation fold\n",
    "4. **Stability Analysis**: Identify stable biomarkers that appear across multiple folds\n",
    "5. **Evaluation**: Assess model performance with multiple metrics\n",
    "6. **Interpretation**: Analyze feature importance using Gini and SHAP approaches\n",
    "\n",
    "## Expected Outputs\n",
    "- Performance metrics for each subtype classification\n",
    "- Stable feature sets specific to each subtype\n",
    "- Comparative analysis of subtype-specific protein signatures\n",
    "- Importance ranking of identified biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import warnings\n",
    "import statistics as stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from matplotlib_venn import venn3\n",
    "from typing import Dict\n",
    "from upsetplot import UpSet\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score, balanced_accuracy_score)\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.dirname(os.getcwd()) + '/data'\n",
    "figure_path = os.path.dirname(os.getcwd()) + '/figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Olink Data\n",
    "df = pd.read_excel(data_path + '/curated/olink.xlsx')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Codon 129', 'SampleID', 'Group', 'Strain', 'age at LP', 'Sex',\n",
    "    'onset-LP', 'onset-death', 'LP-death', 'NP_subtype'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Filter out controls\n",
    "df = df[df['SubGroup'] != 'CTRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SubGroup'], axis=1)\n",
    "y = df['SubGroup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_subtype(X, y, target_subtype, cv, k=50):\n",
    "    \"\"\"\n",
    "    Perform balanced binary classification analysis for a specific subtype vs all others.\n",
    "    \"\"\"\n",
    "    # Create binary labels\n",
    "    y_binary = (y == target_subtype).astype(int)\n",
    "    \n",
    "    # Initialize metrics storage\n",
    "    metrics = {\n",
    "        'Accuracy': [], 'Precision': [], 'Recall': [], \n",
    "        'F1': [], 'ROC-AUC': [], 'Balanced accuracy': []\n",
    "    }\n",
    "    feature_importances = {}  # Store feature importances by feature name\n",
    "    all_selected_features = []  # Store selected features for each fold\n",
    "    feature_shap_values = {}  # Store SHAP values by feature\n",
    "    \n",
    "    # Calculate class weights\n",
    "    n_samples = len(y_binary)\n",
    "    n_positive = sum(y_binary)\n",
    "    class_weight = {0: n_positive/n_samples, \n",
    "                   1: (n_samples-n_positive)/n_samples}\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(cv.split(X, y_binary), 1):\n",
    "        print(f\"Processing {target_subtype} - Fold {fold}\")\n",
    "        \n",
    "        # Split data\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y_binary.iloc[train_idx], y_binary.iloc[test_idx]\n",
    "        \n",
    "        # Feature selection on training data only\n",
    "        selector = SelectKBest(f_classif, k=k)\n",
    "        X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "        X_test_selected = selector.transform(X_test)\n",
    "        \n",
    "        # Store selected features for this fold\n",
    "        fold_features = X.columns[selector.get_support()].tolist()\n",
    "        all_selected_features.append(fold_features)\n",
    "        \n",
    "        # Train model with class balancing\n",
    "        model = RandomForestClassifier(\n",
    "            random_state=42,\n",
    "            class_weight=class_weight,\n",
    "            n_estimators=200\n",
    "        )\n",
    "        model.fit(X_train_selected, y_train)\n",
    "        \n",
    "        # Predictions\n",
    "        y_pred = model.predict(X_test_selected)\n",
    "        y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
    "        metrics['Balanced accuracy'].append(balanced_accuracy_score(y_test, y_pred))\n",
    "        metrics['Precision'].append(precision_score(y_test, y_pred))\n",
    "        metrics['Recall'].append(recall_score(y_test, y_pred))\n",
    "        metrics['F1'].append(f1_score(y_test, y_pred))\n",
    "        metrics['ROC-AUC'].append(roc_auc_score(y_test, y_pred_proba))\n",
    "        \n",
    "        # SHAP analysis\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer(X_test_selected)\n",
    "        \n",
    "        # Store feature importance and SHAP values by feature name\n",
    "        for i, feature in enumerate(fold_features):\n",
    "            if feature not in feature_importances:\n",
    "                feature_importances[feature] = []\n",
    "            if feature not in feature_shap_values:\n",
    "                feature_shap_values[feature] = []\n",
    "            \n",
    "            feature_importances[feature].append(model.feature_importances_[i])\n",
    "            feature_shap_values[feature].append(np.abs(shap_values.values[:, i]).mean())\n",
    "    \n",
    "    # Analyze feature selection stability\n",
    "    feature_stability = {}\n",
    "    all_unique_features = set(feature for fold_features in all_selected_features \n",
    "                            for feature in fold_features)\n",
    "    \n",
    "    for feature in all_unique_features:\n",
    "        feature_stability[feature] = sum(\n",
    "            feature in fold_features \n",
    "            for fold_features in all_selected_features\n",
    "        ) / len(all_selected_features)\n",
    "    \n",
    "    # Get stable features\n",
    "    stable_features = [f for f, stability in feature_stability.items() \n",
    "                      if stability >= 0.6]\n",
    "    \n",
    "    # Calculate mean values for stable features\n",
    "    stable_importance_df = pd.DataFrame({\n",
    "        'Feature': stable_features,\n",
    "        'Stability': [feature_stability[f] for f in stable_features],\n",
    "        'Gini': [np.mean(feature_importances[f]) for f in stable_features],\n",
    "        'SHAP': [np.mean(feature_shap_values[f]) for f in stable_features]\n",
    "    })\n",
    "    \n",
    "    # Sort by SHAP importance\n",
    "    stable_importance_df = stable_importance_df.sort_values('SHAP', ascending=False)\n",
    "    stable_importance_df.to_csv(data_path + '/results/'+ f'{target_subtype}_feature_importance.csv', index=False)\n",
    "        \n",
    "    # Plot top 20 stable features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    n_features = min(20, len(stable_features))\n",
    "    plt.barh(range(n_features), stable_importance_df['SHAP'][:n_features])\n",
    "    plt.yticks(range(n_features), stable_importance_df['Feature'][:n_features])\n",
    "    plt.xlabel('Mean |SHAP value|')\n",
    "    plt.title(f'Top Stable Features for {target_subtype}\\n' + '(Selected in ≥60% of folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figure_path + '/ml_subgroup' + f'/{target_subtype}_top_stable_features.png', dpi=1200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "        \n",
    "    # Print results\n",
    "    print(f\"\\nResults for {target_subtype}:\")\n",
    "    for metric, values in metrics.items():\n",
    "        print(f\"{metric}: {np.mean(values):.4f} (±{np.std(values):.4f})\")\n",
    "    print(f\"\\nNumber of stable features: {len(stable_features)}\")\n",
    "    \n",
    "    return {\n",
    "        'metrics': {k: (np.mean(v), np.std(v)) for k, v in metrics.items()},\n",
    "        'importance': stable_importance_df,\n",
    "        'feature_stability': feature_stability,\n",
    "        'selected_features': stable_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cross-validation object\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Get unique subtypes\n",
    "subtypes = y.unique()\n",
    "\n",
    "# Run for each subtype\n",
    "results = {}\n",
    "for subtype in subtypes:\n",
    "    print(f\"\\nAnalyzing {subtype}...\")\n",
    "    results[subtype] = analyze_subtype(X, y, target_subtype=subtype, cv=cv, k=50)\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame({\n",
    "    subtype: {\n",
    "        'Accuracy': results[subtype]['metrics']['Accuracy'][0],\n",
    "        'Balanced Accuracy': results[subtype]['metrics']['Balanced accuracy'][0],\n",
    "        'ROC-AUC': results[subtype]['metrics']['ROC-AUC'][0]\n",
    "    } for subtype in subtypes\n",
    "}).T\n",
    "\n",
    "print(\"\\nComparison across subtypes:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_proteins = {}\n",
    "for subtype in results:\n",
    "    # Get the stable proteins and their SHAP values\n",
    "    df = results[subtype]['importance']\n",
    "    important_proteins[subtype] = df['Feature'].tolist()\n",
    "\n",
    "# Find unique and shared proteins\n",
    "all_proteins = set()\n",
    "for proteins in important_proteins.values():\n",
    "    all_proteins.update(proteins)\n",
    "\n",
    "# Create sets for easy comparison\n",
    "protein_sets = {subtype: set(proteins) for subtype, proteins in important_proteins.items()}\n",
    "\n",
    "# Find unique proteins for each subtype\n",
    "unique_proteins = {\n",
    "    subtype: protein_sets[subtype] - set.union(*(\n",
    "        protein_sets[other] for other in protein_sets if other != subtype\n",
    "    ))\n",
    "    for subtype in protein_sets\n",
    "}\n",
    "\n",
    "# Find shared proteins\n",
    "shared_proteins = set.intersection(*protein_sets.values())\n",
    "\n",
    "# Create summary DataFrame\n",
    "summary = pd.DataFrame({\n",
    "    'Subtype': list(important_proteins.keys()),\n",
    "    'Total_Stable_Proteins': [len(proteins) for proteins in important_proteins.values()],\n",
    "    'Unique_Proteins': [len(unique_proteins[st]) for st in important_proteins],\n",
    "    'Shared_With_Other_Subtypes': [\n",
    "        len(protein_sets[st] - unique_proteins[st]) \n",
    "        for st in important_proteins\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nProtein Signature Summary:\")\n",
    "print(summary)\n",
    "\n",
    "# For enrichment analysis, you'll need:\n",
    "background_proteins = X.columns.tolist()  # All proteins in your panel\n",
    "\n",
    "# Then for each subtype:\n",
    "for subtype in important_proteins:\n",
    "    print(f\"\\nTop 10 proteins for {subtype}:\")\n",
    "    top_proteins = results[subtype]['importance'].head(10)\n",
    "    print(top_proteins[['Feature', 'SHAP', 'Stability']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_data = []\n",
    "for subtype, res in results.items():\n",
    "    for metric, (mean, std) in res['metrics'].items():\n",
    "       metrics_data.append({\n",
    "          'Subtype': subtype, 'Metric': metric, 'Mean': mean, 'Std': std})\n",
    "    \n",
    "df = pd.DataFrame(metrics_data)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 4)) \n",
    "metrics = df['Metric'].unique()\n",
    "subtypes = df['Subtype'].unique()\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25  # Width of bars\n",
    "    \n",
    "# Plot bars for each subtype\n",
    "for i, subtype in enumerate(subtypes):\n",
    "    subtype_data = df[df['Subtype'] == subtype]\n",
    "    plt.bar(x + i*width, subtype_data['Mean'], width, label=subtype, alpha=0.8)\n",
    "    plt.errorbar(x + i*width, subtype_data['Mean'], yerr=subtype_data['Std'], fmt='none', \n",
    "                 capsize=5, color='black', alpha=0.5)\n",
    "    \n",
    "plt.xlabel('Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Classification Performance Metrics by Subtype')\n",
    "plt.xticks(x + width, metrics, rotation=0)\n",
    "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.savefig(figure_path + '/ml_subgroup/performance_metrics.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = []\n",
    "for subtype, res in results.items():\n",
    "    importance_df = res['importance']\n",
    "    top_features = importance_df.nlargest(20, 'SHAP')\n",
    "    \n",
    "    for _, row in top_features.iterrows():\n",
    "        plot_data.append({'Subtype': subtype, 'Feature': row['Feature'], 'SHAP': row['SHAP'],\n",
    "                          'Stability': row['Stability']})\n",
    "    \n",
    "df = pd.DataFrame(plot_data)\n",
    "plt.figure(figsize=(4, 10))\n",
    "g = sns.scatterplot(data=df, x='Subtype', y='Feature',\n",
    "                    size='SHAP', hue='Stability',\n",
    "                    sizes=(50, 400), alpha=0.6)\n",
    "plt.title('Top Features by Subtype')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(bbox_to_anchor=(0.08, 0.3), loc='upper left', borderaxespad=0)\n",
    "\n",
    "plt.savefig(figure_path + '/ml_subgroup/top_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
