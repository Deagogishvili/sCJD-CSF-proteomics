{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Classification Analysis for Olink Data\n",
    "\n",
    "This notebook performs a machine learning analysis on Olink protein expression data using Random Forest classification. The analysis compares three different approaches:\n",
    "1. Random Forest with all features\n",
    "2. Random Forest with selected features (top 50)\n",
    "3. Random Forest with shuffled labels (control model)\n",
    "\n",
    "## Analysis Steps\n",
    "1. **Data Preprocessing**\n",
    "   - Load Olink protein expression data\n",
    "   - Remove unnecessary columns\n",
    "   - Filter control samples\n",
    "   \n",
    "2. **Model Training**\n",
    "   - Implement 5-fold cross-validation\n",
    "   - Train models with different feature sets\n",
    "   - Generate performance metrics\n",
    "   \n",
    "3. **Evaluation**\n",
    "   - Calculate standard metrics (accuracy, precision, recall, F1, ROC-AUC)\n",
    "   - Generate confusion matrices\n",
    "   - Analyze feature importance using SHAP\n",
    "   - Compare model performances\n",
    "\n",
    "## Expected Outputs\n",
    "- Performance metrics for each model\n",
    "- Confusion matrices\n",
    "- Feature importance plots\n",
    "- SHAP analysis visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import os\n",
    "import warnings\n",
    "import statistics as stat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, \n",
    "                             accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, roc_auc_score)\n",
    "\n",
    "# SHAP for interpretability\n",
    "import shap\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Enable inline plotting for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.dirname(os.getcwd()) + '/data'\n",
    "figure_path = os.path.dirname(os.getcwd()) + '/figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Olink Data\n",
    "df = pd.read_excel(data_path + '/curated/olink.xlsx')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Codon 129', 'SampleID', 'Group', 'Strain', 'age at LP', 'Sex',\n",
    "    'onset-LP', 'onset-death', 'LP-death', 'NP_subtype'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Filter out controls\n",
    "df = df[df['SubGroup'] != 'CTRL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['SubGroup'], axis=1)\n",
    "y = df['SubGroup']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_with_plots(X, y, model, cv, k=None, plot_confusion=False, save_path=None, model_name=\"\"):\n",
    "    accuracies, precisions, recalls, f1_scores, roc_aucs = [], [], [], [], []\n",
    "    all_confusion_matrices = np.zeros((len(y.unique()), len(y.unique())))\n",
    "    classes = sorted(y.unique())\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(cv.split(X, y), 1):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        if k is not None:\n",
    "            selector = SelectKBest(f_classif, k=k)\n",
    "            X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "            X_test_selected = selector.transform(X_test)\n",
    "            X_train, X_test = X_train_selected, X_test_selected\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        \n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "        \n",
    "        y_test_bin = label_binarize(y_test, classes=classes)\n",
    "        roc_auc = roc_auc_score(y_test_bin, y_pred_proba, average='macro', multi_class='ovr')\n",
    "        roc_aucs.append(roc_auc)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=classes)\n",
    "        all_confusion_matrices += cm\n",
    "    \n",
    "    # Average confusion matrix (percentages)\n",
    "    all_confusion_matrices /= all_confusion_matrices.sum(axis=1, keepdims=True)\n",
    "    all_confusion_matrices *= 100\n",
    "    \n",
    "    # Plot Confusion Matrix if requested\n",
    "    if plot_confusion:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(all_confusion_matrices, annot=True, fmt='.2f', cmap='Blues', \n",
    "                   xticklabels=classes, yticklabels=classes)\n",
    "        plt.title(f'Confusion Matrix (Percentage) - {model_name}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(figure_path + f\"/ml_all/confusion_matrix_{model_name}.png\", dpi=1200, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': (np.mean(accuracies), np.std(accuracies)),\n",
    "        'Precision': (np.mean(precisions), np.std(precisions)),\n",
    "        'Recall': (np.mean(recalls), np.std(recalls)),\n",
    "        'F1 Score': (np.mean(f1_scores), np.std(f1_scores)),\n",
    "        'ROC-AUC': (np.mean(roc_aucs), np.std(roc_aucs)),\n",
    "        'Confusion Matrix': all_confusion_matrices\n",
    "    }\n",
    "\n",
    "def plot_metrics_comparison(metrics_original, metrics_reduced, metrics_random):\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'ROC-AUC']\n",
    "    models = ['RF all features', 'RF selected features', 'Random RF']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7, 5))\n",
    "    x = np.arange(len(metrics)) \n",
    "    width = 0.25 \n",
    "    colors = sns.color_palette(\"Set2\", 3)\n",
    "    \n",
    "    for i, (model_metrics, color) in enumerate(zip([metrics_original, metrics_reduced, metrics_random], colors)):\n",
    "        means = [model_metrics[m][0] for m in metrics]\n",
    "        stds = [model_metrics[m][1] for m in metrics]\n",
    "        ax.bar(x + i*width, means, width, label=models[i], yerr=stds, capsize=5, color=color)\n",
    "    \n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(x + width)\n",
    "    ax.set_xticklabels(metrics, fontsize=12)\n",
    "    ax.legend(title='Models', fontsize=10, title_fontsize='12', loc='lower left')\n",
    "    ax.grid(True, which='both', axis='y', linestyle='--', linewidth=0.7, alpha=0.7)\n",
    "    \n",
    "    sns.despine()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figure_path + '/ml_all/model_performance.png', dpi=1200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Define the folder path to save the plots\n",
    "save_path = figure_path\n",
    "\n",
    "# Create StratifiedKFold object\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Model 1: Original Random Forest\n",
    "rf_original = RandomForestClassifier(random_state=42)\n",
    "metrics_original = train_and_evaluate_with_plots(X, y, rf_original, cv, plot_confusion=True, \n",
    "                                               save_path=save_path, model_name=\"RF_original\")\n",
    "\n",
    "# Model 2: Random Forest with reduced features\n",
    "rf_reduced = RandomForestClassifier(random_state=42)\n",
    "metrics_reduced = train_and_evaluate_with_plots(X, y, rf_reduced, cv, k=50, plot_confusion=True, \n",
    "                                              save_path=save_path, model_name=\"RF_reduced\")\n",
    "\n",
    "# Model 3: Random model (shuffled labels)\n",
    "rf_random = RandomForestClassifier(random_state=42)\n",
    "y_shuffled = y.copy()\n",
    "y_shuffled = y_shuffled.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "metrics_random = train_and_evaluate_with_plots(X, y_shuffled, rf_random, cv, plot_confusion=True, \n",
    "                                             save_path=save_path, model_name=\"RF_random\")\n",
    "\n",
    "# Plot comparison\n",
    "plot_metrics_comparison(metrics_original, metrics_reduced, metrics_random)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
