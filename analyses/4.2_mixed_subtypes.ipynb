{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subanalysis related to patients with a neuropathological diagnosis\n",
    "==================================================================================================\n",
    "\n",
    "This notebook performs UMAP and hierarchical clustering considering only patients with a neuropathological diagnosis. Moreover it performs the differential expression analysis between MM(V)1 and MM(V)1+2C sCJD subtypes and plots ROC curves of top differentially expressed biomarkers.\n",
    "\n",
    "Input:\n",
    "------\n",
    "- olink.xlsx: Protein expression data with columns:\n",
    "  * SampleID: Unique sample identifier\n",
    "  * Group: Clinical group classification\n",
    "  * SubGroup: Clinical subgroup\n",
    "  * Strain: Sample strain type\n",
    "  * age at LP: Age at lumbar puncture\n",
    "  * Sex: Patient sex\n",
    "  * [Protein Names]: NPX values for each protein\n",
    "- feature_importance_rankings.csv: List of the top 20 proteins useful for sCJD subtypes classification\n",
    "- differential.csv: Differential expression results including:\n",
    "  * Protein: Protein identifier\n",
    "  * Group comparisons\n",
    "  * P-values\n",
    "  * Q-values (FDR corrected)\n",
    "  * Log2 fold changes\n",
    "  * Beta coefficients\n",
    "\n",
    "Output:\n",
    "-------\n",
    "- UMAP visualisation of all proteomic data for each subtype\n",
    "- UMAP visualisation of top 20 proteins useful for sCJD subtypes classification data \n",
    "- Heatmaps showing the hierarchical clustering \n",
    "- mixed.xlsx: Differential expression results including:\n",
    "  * Protein: Protein identifier\n",
    "  * Group comparisons\n",
    "  * P-values\n",
    "  * Q-values (FDR corrected)\n",
    "  * Log2 fold changes\n",
    "  * Beta coefficients\n",
    "- Volcano plot to show the results of the differential expression analysis\n",
    "- ROC curves of top differentially expressed proteins in distinguishing MM(V)1 vs MM(V)1+2C\n",
    "\n",
    "Analysis Steps:\n",
    "---------------\n",
    "Details regarding the analysis steps are provided in the respective notebooks as follows: \n",
    "- UMAP: 01_demographics.ipynb\n",
    "- Hierarchical clustering: 03_hierarchical_clustering.ipynb\n",
    "- Differential expression analysis: 02_differential.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Statistical analysis\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# Machine learning & data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Dimensionality reduction & clustering\n",
    "from umap import UMAP\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "from adjustText import adjust_text\n",
    "\n",
    "# ROC curve & AUC\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define path\n",
    "data_path = os.path.dirname(os.getcwd()) + '/data/'\n",
    "figure_path = os.path.dirname(os.getcwd()) + '/figures/mixed_subtypes'\n",
    "results_path = os.path.dirname(os.getcwd()) + '/data/results/differential'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform UMAP on proteomic data of patients with a neuropathological diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "df = pd.read_excel(data_path + '/curated/olink.xlsx')\n",
    "\n",
    "# Keep necessary columns from Olink data\n",
    "columns_to_drop = ['age at LP', 'Sex', 'Codon 129',\n",
    "                   'onset-LP', 'onset-death', 'LP-death', 'Group', 'Strain', 'SubGroup']\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "df = df[~df['NP_subtype'].isin(['VV2 probable', 'MV2K probable', 'MM(V)1 probable', 'CTRL'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check total number of NaN values in the dataset\n",
    "total_nan = df.isna().sum().sum()\n",
    "print(f\"Total number of NaN values in the dataset: {total_nan}\")\n",
    "\n",
    "# Check NaN values per column\n",
    "nan_per_column = df.isna().sum()\n",
    "\n",
    "# Display only columns that have NaN values\n",
    "columns_with_nan = nan_per_column[nan_per_column > 0]\n",
    "\n",
    "if len(columns_with_nan) > 0:\n",
    "    print(\"\\nColumns with NaN values:\")\n",
    "    print(columns_with_nan)\n",
    "    \n",
    "    # Calculate percentage of NaN values per column\n",
    "    nan_percentage = (columns_with_nan / len(df)) * 100\n",
    "    print(\"\\nPercentage of NaN values per column:\")\n",
    "    print(nan_percentage)\n",
    "else:\n",
    "    print(\"\\nNo columns contain NaN values\")\n",
    "\n",
    "# Check if any rows have all NaN values\n",
    "rows_all_nan = df[df.isna().all(axis=1)]\n",
    "print(f\"\\nNumber of rows with all NaN values: {len(rows_all_nan)}\")\n",
    "\n",
    "# Check if any rows have any NaN values\n",
    "rows_with_nan = df[df.isna().any(axis=1)]\n",
    "print(f\"Number of rows containing at least one NaN value: {len(rows_with_nan)}\")\n",
    "\n",
    "if len(rows_with_nan) > 0:\n",
    "    print(\"\\nSample IDs of rows with NaN values:\")\n",
    "    print(rows_with_nan['SampleID'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform UMAP on all proteomic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap(df, figure_path):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Define matching colors\n",
    "    colors = {\n",
    "        'MV2K': '#2ecc71', # green\n",
    "        #'MV2K probable': '#2ecc71', # green\n",
    "        'MV2K+2C': '#27ae60', # dark green\n",
    "        'VV2': '#e74c3c',  # red\n",
    "        #'VV2 probable': '#e74c3c',  # red\n",
    "        'MM(V)1': '#3498db', # blue \n",
    "        #'MM(V)1 probable': '#8e44ad', # purple\n",
    "        'MM(V)1+2C': '#f39c12', # orange\n",
    "        #'CTRL': '#333c42', # grey\n",
    "    }\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df.drop(['SampleID', 'NP_subtype'], axis=1)\n",
    "    \n",
    "    # Scale the data\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Perform UMAP\n",
    "    umap_embedding = UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        random_state=42\n",
    "    ).fit_transform(X_scaled)\n",
    "    \n",
    "    # Plot UMAP results for each subtype\n",
    "    for subtype in df['NP_subtype'].unique():\n",
    "        mask = df['NP_subtype'] == subtype\n",
    "        ax.scatter(\n",
    "            umap_embedding[mask, 0],\n",
    "            umap_embedding[mask, 1],\n",
    "            c=colors[subtype],\n",
    "            label=f\"{subtype} (n={sum(mask)})\",\n",
    "            alpha=0.7\n",
    "        )\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title('UMAP Analysis by sCJD Subtype', pad=20, fontsize=14)\n",
    "    plt.xlabel('UMAP1', fontsize=12)\n",
    "    plt.ylabel('UMAP2', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Move legend\n",
    "    plt.legend(bbox_to_anchor=(0.0005, 0.0005), loc='lower left', frameon=True, framealpha=0.8)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "    \n",
    "    # Save and show\n",
    "    plt.savefig(figure_path + '/umap_NP_cjd_subtype.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate plot\n",
    "fig = plot_umap(df, figure_path)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform UMAP on top 20 proteins for subtype classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import feature importance from ML results\n",
    "df = pd.read_excel(data_path + '/curated/olink.xlsx')\n",
    "\n",
    "feature_importance_rankings = pd.read_csv(data_path + '/results/feature_importance_rankings.csv')\n",
    "top_biomarkers = list(feature_importance_rankings['Feature'].head(20))\n",
    "\n",
    "# Select the columns\n",
    "columns_to_select = top_biomarkers + ['SampleID', 'NP_subtype']\n",
    "df = df[columns_to_select]\n",
    "df = df[~df['NP_subtype'].isin(['VV2 probable', 'MV2K probable', 'MM(V)1 probable', 'CTRL'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_umap(df, figure_path):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    # Define matching colors\n",
    "    colors = {\n",
    "        'MV2K': '#2ecc71', # green\n",
    "        #'MV2K probable': '#2ecc71', # green\n",
    "        'MV2K+2C': '#27ae60', # dark green\n",
    "        'VV2': '#e74c3c',  # red\n",
    "        #'VV2 probable': '#e74c3c',  # red\n",
    "        'MM(V)1': '#3498db', # blue \n",
    "        #'MM(V)1 probable': '#8e44ad', # purple\n",
    "        'MM(V)1+2C': '#f39c12', # orange\n",
    "        #'CTRL': '#333c42', # grey\n",
    "    }\n",
    "    \n",
    "    # Prepare data\n",
    "    X = df.drop(['SampleID', 'NP_subtype'], axis=1)\n",
    "    \n",
    "    # Scale the data\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    # Perform UMAP\n",
    "    umap_embedding = UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.1,\n",
    "        n_components=2,\n",
    "        random_state=42\n",
    "    ).fit_transform(X_scaled)\n",
    "    \n",
    "    # Plot UMAP results for each subtype\n",
    "    for subtype in df['NP_subtype'].unique():\n",
    "        mask = df['NP_subtype'] == subtype\n",
    "        ax.scatter(\n",
    "            umap_embedding[mask, 0],\n",
    "            umap_embedding[mask, 1],\n",
    "            c=colors[subtype],\n",
    "            label=f\"{subtype} (n={sum(mask)})\",\n",
    "            alpha=0.7\n",
    "        )\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title('UMAP Analysis by sCJD Subtype', pad=20, fontsize=14)\n",
    "    plt.xlabel('UMAP1', fontsize=12)\n",
    "    plt.ylabel('UMAP2', fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Move legend\n",
    "    plt.legend(bbox_to_anchor=(0.0005, 0.9995), loc='upper left', frameon=True, framealpha=0.8)\n",
    "    \n",
    "    # Adjust layout\n",
    "    plt.subplots_adjust(right=0.85)\n",
    "    \n",
    "    # Save and show\n",
    "    plt.savefig(figure_path + '/umap_NP_cjd_subtype_top20_subtype.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate plot\n",
    "fig = plot_umap(df, figure_path)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Hierarchical clustering including only patients with a neuropathological diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean data\n",
    "def load_and_clean_data():\n",
    "    df_results = pd.read_csv(results_path + '/differential.csv')\n",
    "    df_olink = pd.read_excel(data_path + 'curated/olink.xlsx')\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    columns_to_drop = ['SubGroup', 'Group', 'Strain', 'age at LP', 'Sex', 'Codon 129', 'onset-LP', 'onset-death', 'LP-death']\n",
    "    df_olink = df_olink.drop(columns=columns_to_drop)\n",
    "    df_olink = df_olink[df_olink['NP_subtype'].isin(['MM(V)1', 'MM(V)1+2C', 'VV2', 'MV2K', 'MV2K+2C'])]\n",
    "\n",
    "    return df_results, df_olink\n",
    "\n",
    "# Filter significant\n",
    "def filter_significant_results(df_results, comparisons):\n",
    "    filtered_df = df_results[df_results['Significant'] == True]\n",
    "    filtered_comparisons_df = filtered_df[filtered_df['Group1_vs_Group2'].isin(comparisons)]\n",
    "\n",
    "    hc_list = []\n",
    "    for comparison in comparisons:\n",
    "        comparison_df = filtered_comparisons_df[filtered_comparisons_df['Group1_vs_Group2'] == comparison]\n",
    "        top_50 = comparison_df.nsmallest(50, 'Q_Value')[['Protein', 'Q_Value', 'Group1_vs_Group2']]\n",
    "        hc_list.append(top_50)\n",
    "\n",
    "    HC_list = pd.concat(hc_list)\n",
    "    proteins_to_include = HC_list['Protein'].unique()\n",
    "\n",
    "    # Filter results per comparison\n",
    "    filtered_dfs = {}\n",
    "    for comp in comparisons:\n",
    "        filtered_dfs[comp] = df_results[(df_results['Significant'] == True) & (df_results['Group1_vs_Group2'] == comp)]\n",
    "        filtered_dfs[comp] = filtered_dfs[comp][filtered_dfs[comp]['Protein'].isin(HC_list['Protein'])]\n",
    "\n",
    "    return proteins_to_include, filtered_dfs\n",
    "\n",
    "# Clustering\n",
    "def perform_clustering(protein_data_normalized):\n",
    "    protein_corr = protein_data_normalized.corr(method='spearman')\n",
    "    sample_corr = protein_data_normalized.T.corr(method='spearman')\n",
    "\n",
    "    protein_dist = 1 - protein_corr\n",
    "    sample_dist = 1 - sample_corr\n",
    "\n",
    "    protein_condensed = pdist(protein_dist.to_numpy())\n",
    "    sample_condensed = pdist(sample_dist.to_numpy())\n",
    "\n",
    "    protein_linkage = sch.linkage(protein_condensed, method='average')\n",
    "    sample_linkage = sch.linkage(sample_condensed, method='average')\n",
    "\n",
    "    return protein_linkage, sample_linkage\n",
    "\n",
    "# Plot Heatmap\n",
    "def plot_heatmap(protein_data, protein_data_normalized, protein_linkage, sample_linkage, \n",
    "                 filtered_dfs, proteins_to_include, comparisons, df_olink, figure_path):\n",
    "    # Map colors for proteins\n",
    "    protein_colors = {comp: {} for comp in comparisons}\n",
    "    for comp in comparisons:\n",
    "        for protein in proteins_to_include:\n",
    "            q_value = filtered_dfs[comp].loc[filtered_dfs[comp]['Protein'] == protein, 'Q_Value'].min()\n",
    "\n",
    "            # Color coding based on significance levels\n",
    "            if q_value < 0.01:\n",
    "                protein_colors[comp][protein] = 'deepskyblue'\n",
    "            elif q_value < 0.05:\n",
    "                protein_colors[comp][protein] = 'lightblue'\n",
    "            else:\n",
    "                protein_colors[comp][protein] = 'gainsboro'\n",
    "\n",
    "    protein_colors_combined = pd.DataFrame({\n",
    "        comp: [protein_colors[comp].get(protein, 'lightgray') for protein in protein_data.columns]\n",
    "        for comp in comparisons\n",
    "    })\n",
    "\n",
    "    # Define color mapping for SubGroup\n",
    "    group_colors = {'MM(V)1': 'yellow', 'MM(V)1+2C': 'coral', 'VV2': 'purple', 'MV2K': 'green', 'MV2K+2C': 'teal'}\n",
    "    col_colors = df_olink.set_index('SampleID').loc[protein_data.index, 'NP_subtype'].map(group_colors).values\n",
    "\n",
    "    # Plot the heatmap\n",
    "    g = sns.clustermap(\n",
    "        protein_data_normalized.T,\n",
    "        row_linkage=protein_linkage,\n",
    "        col_linkage=sample_linkage,\n",
    "        cmap='bwr',\n",
    "        col_colors=col_colors,\n",
    "        xticklabels=False,\n",
    "        yticklabels=False,  # To display protein labels, use yticklabels=protein_data.columns\n",
    "        figsize=(12, 8),  # Increase figure size for better spacing\n",
    "        vmin=-3,\n",
    "        vmax=3,\n",
    "        row_colors=protein_colors_combined.values.T,\n",
    "        cbar_pos=(1.001, 0.3, 0.02, 0.3),\n",
    "        dendrogram_ratio=(0.05, 0.1)\n",
    "    )\n",
    "\n",
    "    # Remove axis labels\n",
    "    g.ax_heatmap.set_xlabel('')\n",
    "    g.ax_heatmap.set_ylabel('')\n",
    "\n",
    "    # Add legend for SubGroup colors\n",
    "    handles_group = [Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=10)\n",
    "                     for color in group_colors.values()]\n",
    "    labels_group = list(group_colors.keys())\n",
    "\n",
    "    g.ax_heatmap.legend(handles=handles_group, labels=labels_group, loc='upper left', title='Diagnostic Group',\n",
    "                        bbox_to_anchor=(1.001, 1.0), ncol=1)\n",
    "\n",
    "    # Create a second legend for significance levels\n",
    "    handles_qvalue = [\n",
    "        Patch(color='deepskyblue', label='q < 0.01'),\n",
    "        Patch(color='lightblue', label='q < 0.05'),\n",
    "        Patch(color='gainsboro', label='Non-significant')\n",
    "    ]\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.legend(handles=handles_qvalue, title='Significance of DEA', loc='upper center',\n",
    "              bbox_to_anchor=(-40.55, -0.85), ncol=3)  # Positioned below the heatmap\n",
    "\n",
    "    # Function to add labels to comparisons\n",
    "    def add_comparison_label(ax, index, comparison, vertical_spacing=10.3):\n",
    "        ax.text(index - 50, -vertical_spacing, comparison, ha='center', va='center', fontsize=10, color='black',\n",
    "                rotation=90, bbox=dict(facecolor='white', edgecolor='None', boxstyle='round,pad=0.5'))\n",
    "\n",
    "    # Add labels for each comparison with custom positioning\n",
    "    for i, comp in enumerate(comparisons):\n",
    "        if comp == \"VV2 vs MM(V)1\":\n",
    "            add_comparison_label(g.ax_heatmap, i + 45, comp, vertical_spacing=9)\n",
    "        elif comp == \"MV2K vs VV2\":\n",
    "            add_comparison_label(g.ax_heatmap, i + 47, comp, vertical_spacing=9)\n",
    "        elif comp == \"MV2K vs MM(V)1\":\n",
    "            add_comparison_label(g.ax_heatmap, i + 46, comp, vertical_spacing=9)\n",
    "        else:\n",
    "            add_comparison_label(g.ax_heatmap, i, comp)\n",
    "\n",
    "    # Save the figure\n",
    "    output_file = os.path.join(figure_path, \"heatmap_NP.png\")\n",
    "    plt.savefig(output_file, dpi=1200, bbox_inches='tight')  \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Data norm\n",
    "def preprocess_and_normalize(protein_data, proteins_to_include):\n",
    "    # Normalize by total protein per sample\n",
    "    total_protein_per_sample = protein_data.sum(axis=1)\n",
    "    protein_data_normalized = protein_data.div(total_protein_per_sample, axis=0)\n",
    "\n",
    "    # Z-score normalization\n",
    "    protein_data_normalized = (protein_data_normalized - protein_data_normalized.mean(axis=0)) / protein_data_normalized.std(axis=0)\n",
    "\n",
    "    return protein_data_normalized\n",
    "\n",
    "def main():\n",
    "    \"\"\"Executes the entire data processing and visualization pipeline.\"\"\"\n",
    "    df_results, df_olink = load_and_clean_data()\n",
    "    \n",
    "    # Define comparisons (needed for the heatmap function)\n",
    "    comparisons = ['VV2 vs MM(V)1', 'MV2K vs MM(V)1', 'MV2K vs VV2']\n",
    "    \n",
    "    proteins_to_include, filtered_dfs = filter_significant_results(df_results, comparisons)\n",
    "    \n",
    "    # Define protein_data here (original protein data matrix before normalization)\n",
    "    protein_data = df_olink.set_index('SampleID').drop(columns=['NP_subtype'])\n",
    "    protein_data = protein_data[proteins_to_include]\n",
    "    \n",
    "    # Pass protein_data to preprocess_and_normalize function\n",
    "    protein_data_normalized = preprocess_and_normalize(protein_data, proteins_to_include)\n",
    "    \n",
    "    protein_linkage, sample_linkage = perform_clustering(protein_data_normalized)\n",
    "    plot_heatmap(protein_data, protein_data_normalized, protein_linkage, sample_linkage, filtered_dfs, proteins_to_include, comparisons, df_olink, figure_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Differential Expression Analysis between MM(V)1 and MM(V)1+2C subgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Olink Data\n",
    "df = pd.read_excel(data_path + 'curated/olink.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "columns_to_drop = [\n",
    "    'Codon 129',\n",
    "    'onset-LP', 'onset-death', 'LP-death', 'Group', 'SubGroup', 'Strain'\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Pivoting the DataFrame in long format\n",
    "df_pivoted = df.melt(\n",
    "    id_vars=['SampleID', 'NP_subtype', 'age at LP', 'Sex'],  \n",
    "    var_name='Assay',  \n",
    "    value_name='NPX' \n",
    ")\n",
    "\n",
    "# Setting index\n",
    "df_pivoted.set_index('SampleID', inplace=True)\n",
    "df = df_pivoted.copy()\n",
    "\n",
    "# Rename column for consistency\n",
    "df = df.rename(columns={\"age at LP\": \"age_at_LP\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for the specific pairwise comparison\n",
    "def perform_differential_expression(df, results, threshold=0.05):\n",
    "    # Define the groups to compare\n",
    "    group1, group2 = \"MM(V)1\", \"MM(V)1+2C\"\n",
    "    \n",
    "    # Filter data for only these groups\n",
    "    subset = df[df[\"NP_subtype\"].isin([group1, group2])].copy()\n",
    "    \n",
    "    # Encode groups as binary (1 for MM(V)1, 0 for MM(V)1+2C)\n",
    "    subset[\"NP_subtype\"] = subset[\"NP_subtype\"].map({group1: 1, group2: 0})\n",
    "    \n",
    "    for protein in subset[\"Assay\"].unique():\n",
    "        protein_subset = subset[subset[\"Assay\"] == protein]\n",
    "\n",
    "        if len(protein_subset) < 2:\n",
    "            continue  # Skip if insufficient data\n",
    "\n",
    "        # Define models\n",
    "        formula1 = \"NPX ~ age_at_LP + Sex\"\n",
    "        formula2 = \"NPX ~ age_at_LP + Sex + NP_subtype\"\n",
    "\n",
    "        # Fit models\n",
    "        model1 = ols(formula1, data=protein_subset).fit()\n",
    "        model2 = ols(formula2, data=protein_subset).fit()\n",
    "\n",
    "        # Perform ANOVA\n",
    "        anova_results = anova_lm(model1, model2)\n",
    "        p_value = anova_results[\"Pr(>F)\"][1]  # Extract p-value\n",
    "\n",
    "        # Calculate log2 fold change\n",
    "        vals1 = protein_subset[protein_subset[\"NP_subtype\"] == 1][\"NPX\"]\n",
    "        vals2 = protein_subset[protein_subset[\"NP_subtype\"] == 0][\"NPX\"]\n",
    "        log2_fold_change = vals1.mean() - vals2.mean() if len(vals1) > 0 and len(vals2) > 0 else np.nan\n",
    "\n",
    "        # Extract beta coefficient\n",
    "        beta_coefficient = model2.params.get(\"NP_subtype\", np.nan)\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            \"Protein\": protein,\n",
    "            \"Group_Col\": \"NP_subtype\",\n",
    "            \"Group1\": group1,\n",
    "            \"Group2\": group2,\n",
    "            \"Group1_vs_Group2\": f\"{group1} vs {group2}\",\n",
    "            \"F_P_Value\": p_value,\n",
    "            \"Log2_Fold_Change\": log2_fold_change,\n",
    "            \"Beta_Coefficient\": beta_coefficient\n",
    "        })\n",
    "\n",
    "# Run analysis\n",
    "results = []\n",
    "perform_differential_expression(df, results)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Apply FDR correction\n",
    "results_df[\"Q_Value\"] = multipletests(results_df[\"F_P_Value\"], method=\"fdr_bh\")[1]\n",
    "results_df[\"Significant\"] = results_df[\"Q_Value\"] < 0.05\n",
    "\n",
    "# Save results\n",
    "output_file = os.path.join(results_path, \"mixed.xlsx\")\n",
    "results_df.to_excel(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframe\n",
    "results_df = pd.read_excel(results_path + '/mixed.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating the volcano plot based on Beta Coefficient\n",
    "def create_volcano_plot_beta(results, title, figure_path, threshold=0.05):\n",
    "    plt.figure(figsize=(6, 8))\n",
    "    \n",
    "    # Scatter plot with beta coefficient vs -log10 Q-value\n",
    "    plt.scatter(results['Beta_Coefficient'], \n",
    "                -np.log10(results['Q_Value']), \n",
    "                alpha=0.5, color='#87cefa', label=\"Not Significant\")  # Light Sky Blue\n",
    "\n",
    "    # Highlight significant results based only on Q-value threshold\n",
    "    significant = results[results['Q_Value'] < threshold]\n",
    "    \n",
    "    # Sort by Q-value to get the most significant ones\n",
    "    significant_sorted = significant.sort_values(by='Q_Value').head(25)\n",
    "    \n",
    "    # Highlight significant results \n",
    "    plt.scatter(significant_sorted['Beta_Coefficient'], \n",
    "                -np.log10(significant_sorted['Q_Value']), \n",
    "                color='#87cefa', alpha=0.7, label=\"Significant\")\n",
    "    \n",
    "    # Threshold line for Q-value\n",
    "    plt.axhline(-np.log10(threshold), color='darkred', linestyle='--', label=f'P-value threshold={threshold}')\n",
    "\n",
    "    # Add a vertical line at Beta Coefficient = 0\n",
    "    plt.axvline(0, color='darkred', linestyle='--', label='Beta Coefficient = 0')\n",
    "    \n",
    "    # Increase the Y-axis range to give more space to significant proteins\n",
    "    plt.ylim(0, max(-np.log10(results['Q_Value'])) + 1)\n",
    "    \n",
    "    # Prepare the text labels (protein names) for the significant points\n",
    "    texts = []\n",
    "    for _, row in significant_sorted.iterrows():\n",
    "        text = plt.text(row['Beta_Coefficient'] + 0.05,  # Increase offset to X position\n",
    "                        -np.log10(row['Q_Value']) + 0.05,  # Increase offset to Y position\n",
    "                        row['Protein'], \n",
    "                        fontsize=8,\n",
    "                        color='black',\n",
    "                        ha='left', va='bottom')\n",
    "        texts.append(text)\n",
    "    \n",
    "    # Adjust text to avoid overlap using adjustText\n",
    "    adjust_text(texts, \n",
    "                only_move={'points': 'xy', 'texts': 'xy'},  \n",
    "                expand_text=(1.3, 1.3),  # More space for text expansion\n",
    "                force_text=0.05,  \n",
    "                lim=200)  \n",
    "    \n",
    "    # Axis labels and title\n",
    "    plt.xlabel('Beta Coefficient')\n",
    "    plt.ylabel('-Log10 Q-value')\n",
    "    plt.title(f\"{title}\")\n",
    "    \n",
    "    # Save the plot with high resolution and tight layout\n",
    "    plt.tight_layout()\n",
    "    #os.makedirs(os.path.dirname(figure_path), exist_ok=True)  # Create directory if it doesn't exist\n",
    "    plt.savefig(figure_path, dpi=1200, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Function to clean up the title for a valid file name\n",
    "def clean_filename(title):\n",
    "    return title.replace(\":\", \"_\").replace(\" \", \"_\")\n",
    "\n",
    "# Filter the results for MM(V)1 vs MM(V)1+2C\n",
    "subset = results_df[(results_df['Group1'] == \"MM(V)1\") & (results_df['Group2'] == \"MM(V)1+2C\")]\n",
    "\n",
    "if not subset.empty:\n",
    "    # Create a title and clean it for the filename\n",
    "    title = \"MM(V)1 vs MM(V)1+2C\"\n",
    "    cleaned_title = clean_filename(title)\n",
    "\n",
    "    filename = f\"{cleaned_title}2.png\"\n",
    "    plot_path = os.path.join(figure_path, filename)\n",
    "    \n",
    "    # Create the volcano plot using Beta Coefficient\n",
    "    create_volcano_plot_beta(subset, title, plot_path)\n",
    "    print(f\"Saved: {plot_path}\")\n",
    "else:\n",
    "    print(\"No data available for MM(V)1 vs MM(V)1+2C comparison.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
